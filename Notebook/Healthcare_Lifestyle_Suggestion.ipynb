{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Capstone Fix.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y0s0Eya9JCr",
        "outputId": "7c9bb45e-29d1-4d8c-e29e-8c32c5dd204c"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "id": "0y0s0Eya9JCr",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5a/2497b3ba86f5f1c2c7539e0bc5d957146a5ed71acfb6c66f644974af4309/tensorflowjs-3.6.0-py3-none-any.whl (63kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 20kB 15.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 30kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 40kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Collecting tensorflow-hub<0.10,>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/83/a7df82744a794107641dad1decaad017d82e25f0e1f761ac9204829eef96/tensorflow_hub-0.9.0-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (3.12.4)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.34.1)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.5.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (56.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.30.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Installing collected packages: tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: tensorflow-hub 0.12.0\n",
            "    Uninstalling tensorflow-hub-0.12.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.12.0\n",
            "Successfully installed tensorflow-hub-0.9.0 tensorflowjs-3.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99978154"
      },
      "source": [
        "#Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
      ],
      "id": "99978154",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de796c22"
      },
      "source": [
        "ss_d = StandardScaler()\n",
        "ss_h = StandardScaler()\n",
        "ss_s = StandardScaler()\n",
        "tsize = 0.2\n",
        "\n",
        "def get_model_diabetes():\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=tsize, random_state=0)\n",
        "    print('x_train size: {}, x_test size: {}'.format(x_train.shape, x_test.shape))\n",
        "    print('y_train size: {}, y_test size: {}'.format(y_train.shape, y_test.shape))\n",
        "    x_train = ss_d.fit_transform(x_train)\n",
        "    x_test = ss_d.transform(x_test)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(16, activation='relu', input_shape=[8]),\n",
        "        tf.keras.layers.Dense(16, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                    loss='BinaryCrossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, validation_data = (x_test, y_test), batch_size = 32, epochs = 200, shuffle = True)\n",
        "    return model\n",
        "\n",
        "def get_model_heart():\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x1, y1, test_size=tsize, random_state=0)\n",
        "    print('x_train size: {}, x_test size: {}'.format(x_train.shape, x_test.shape))\n",
        "    print('y_train size: {}, y_test size: {}'.format(y_train.shape, y_test.shape))\n",
        "    x_train = ss_h.fit_transform(x_train)\n",
        "    x_test = ss_h.transform(x_test)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(16, activation='relu', input_shape=[13]),\n",
        "        tf.keras.layers.Dense(16, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                    loss='BinaryCrossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, validation_data = (x_test, y_test), batch_size = 32, epochs = 100, shuffle = True)\n",
        "    return model\n",
        "\n",
        "def get_model_stroke():\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x2, y2, test_size=tsize, random_state=0)\n",
        "    print('x_train size: {}, x_test size: {}'.format(x_train.shape, x_test.shape))\n",
        "    print('y_train size: {}, y_test size: {}'.format(y_train.shape, y_test.shape))\n",
        "    x_train = ss_s.fit_transform(x_train)\n",
        "    x_test = ss_s.transform(x_test)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(16, activation='relu', input_shape=[10]),\n",
        "        tf.keras.layers.Dense(16, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                    loss='BinaryCrossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, validation_data = (x_test, y_test), batch_size = 32, epochs = 25, shuffle = True)\n",
        "    return model\n",
        "\n",
        "def predict_diabetes(Pregnancies, Glucose, BP, SkinThickness, Insulin, BMI, DPF, Age):\n",
        "    preg = int(Pregnancies)\n",
        "    glucose = float(Glucose)\n",
        "    bp = float(BP)\n",
        "    st = float(SkinThickness)\n",
        "    insulin = float(Insulin)\n",
        "    bmi = float(BMI)\n",
        "    dpf = float(DPF)\n",
        "    age = int(Age)\n",
        "\n",
        "    x = [[preg, glucose, bp, st, insulin, bmi, dpf, age]]\n",
        "    x = ss_d.transform(x)\n",
        "\n",
        "    return model_d.predict(x)[0][0]\n",
        "\n",
        "def predict_heart(age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldpeak,slope,ca,thal):\n",
        "    x = [[age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldpeak,slope,ca,thal]]\n",
        "    x = ss_h.transform(x)\n",
        "\n",
        "    return model_h.predict(x)[0][0]\n",
        "\n",
        "def predict_stroke(gender,age,hypertension,heart_disease,ever_married,work_type,Residence_type,avg_glucose_level,bmi,smoking_status):\n",
        "    x = [[gender,age,hypertension,heart_disease,ever_married,work_type,Residence_type,avg_glucose_level,bmi,smoking_status]]\n",
        "    x = ss_s.transform(x)\n",
        "\n",
        "    return model_s.predict(x)[0][0]"
      ],
      "id": "de796c22",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "677bb3e2"
      },
      "source": [
        "#Loading Data\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "df1 = pd.read_csv('heart.csv')\n",
        "df2 = pd.read_csv('healthcare-dataset-stroke-data.csv')"
      ],
      "id": "677bb3e2",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dfbfb56"
      },
      "source": [
        "#Preparing Diabetes\n",
        "df = df.rename(columns={'BloodPressure':'BP', 'DiabetesPedigreeFunction':'DPF'})\n",
        "df[['Glucose', 'BP', 'SkinThickness', 'Insulin',\n",
        "         'BMI', 'DPF']] = df[['Glucose', 'BP', 'SkinThickness', 'Insulin',\n",
        "       'BMI', 'DPF']].replace(0, np.NaN)\n",
        "\n",
        "df['Glucose'].fillna(df['Glucose'].mean(), inplace=True)\n",
        "df['BP'].fillna(df['BP'].mean(), inplace=True)\n",
        "df['SkinThickness'].fillna(df['SkinThickness'].median(), inplace=True)\n",
        "df['Insulin'].fillna(df['Insulin'].median(), inplace=True)\n",
        "df['BMI'].fillna(df['BMI'].median(), inplace=True)\n",
        "\n",
        "x = df.drop(columns=['Outcome'])\n",
        "y = df['Outcome']"
      ],
      "id": "3dfbfb56",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71328979"
      },
      "source": [
        "#Preparing Heart\n",
        "x1 = df1.drop(columns=['target'])\n",
        "y1 = df1['target']"
      ],
      "id": "71328979",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "799cac97"
      },
      "source": [
        "#Preparing Stroke\n",
        "df2 = df2.rename(columns={'heart_disease':'HD', 'ever_married':'EM', 'work_type':'WT', 'Residence_type':'RT','avg_glucose':'AG', 'smoking_status':'SS'})\n",
        "df2['bmi'].fillna(df2['bmi'].median(), inplace=True)\n",
        "\n",
        "df2 = df2[:1001]\n",
        "\n",
        "x2 = df2.drop(columns=['stroke', 'id'])\n",
        "y2 = df2['stroke']"
      ],
      "id": "799cac97",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3671977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb33ed7-9f91-45ef-97da-5379e00e1901"
      },
      "source": [
        "model_d = get_model_diabetes()\n"
      ],
      "id": "c3671977",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train size: (1600, 8), x_test size: (400, 8)\n",
            "y_train size: (1600,), y_test size: (400,)\n",
            "Epoch 1/200\n",
            "50/50 [==============================] - 1s 5ms/step - loss: 0.7263 - accuracy: 0.4294 - val_loss: 0.6809 - val_accuracy: 0.6125\n",
            "Epoch 2/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.7088 - val_loss: 0.6207 - val_accuracy: 0.7375\n",
            "Epoch 3/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7462 - val_loss: 0.5607 - val_accuracy: 0.7400\n",
            "Epoch 4/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7550 - val_loss: 0.5072 - val_accuracy: 0.7575\n",
            "Epoch 5/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7638 - val_loss: 0.4780 - val_accuracy: 0.7700\n",
            "Epoch 6/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7700 - val_loss: 0.4637 - val_accuracy: 0.7875\n",
            "Epoch 7/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7775 - val_loss: 0.4562 - val_accuracy: 0.7925\n",
            "Epoch 8/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7850 - val_loss: 0.4508 - val_accuracy: 0.7900\n",
            "Epoch 9/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7850 - val_loss: 0.4461 - val_accuracy: 0.7950\n",
            "Epoch 10/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7925 - val_loss: 0.4439 - val_accuracy: 0.7875\n",
            "Epoch 11/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7937 - val_loss: 0.4393 - val_accuracy: 0.7925\n",
            "Epoch 12/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7925 - val_loss: 0.4361 - val_accuracy: 0.7850\n",
            "Epoch 13/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7912 - val_loss: 0.4335 - val_accuracy: 0.7900\n",
            "Epoch 14/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7956 - val_loss: 0.4312 - val_accuracy: 0.7800\n",
            "Epoch 15/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7950 - val_loss: 0.4298 - val_accuracy: 0.7775\n",
            "Epoch 16/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7962 - val_loss: 0.4277 - val_accuracy: 0.7725\n",
            "Epoch 17/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7975 - val_loss: 0.4260 - val_accuracy: 0.7750\n",
            "Epoch 18/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7975 - val_loss: 0.4252 - val_accuracy: 0.7750\n",
            "Epoch 19/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8000 - val_loss: 0.4248 - val_accuracy: 0.7800\n",
            "Epoch 20/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8000 - val_loss: 0.4236 - val_accuracy: 0.7775\n",
            "Epoch 21/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.4221 - val_accuracy: 0.7800\n",
            "Epoch 22/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8025 - val_loss: 0.4202 - val_accuracy: 0.7825\n",
            "Epoch 23/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7975 - val_loss: 0.4191 - val_accuracy: 0.7850\n",
            "Epoch 24/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.4173 - val_accuracy: 0.7900\n",
            "Epoch 25/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8075 - val_loss: 0.4147 - val_accuracy: 0.7900\n",
            "Epoch 26/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8106 - val_loss: 0.4147 - val_accuracy: 0.7900\n",
            "Epoch 27/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8106 - val_loss: 0.4128 - val_accuracy: 0.7925\n",
            "Epoch 28/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8075 - val_loss: 0.4111 - val_accuracy: 0.7900\n",
            "Epoch 29/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8169 - val_loss: 0.4091 - val_accuracy: 0.7925\n",
            "Epoch 30/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8163 - val_loss: 0.4087 - val_accuracy: 0.8000\n",
            "Epoch 31/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8106 - val_loss: 0.4073 - val_accuracy: 0.8000\n",
            "Epoch 32/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8169 - val_loss: 0.4066 - val_accuracy: 0.8025\n",
            "Epoch 33/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8194 - val_loss: 0.4044 - val_accuracy: 0.8025\n",
            "Epoch 34/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8169 - val_loss: 0.4032 - val_accuracy: 0.8000\n",
            "Epoch 35/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8225 - val_loss: 0.4028 - val_accuracy: 0.7975\n",
            "Epoch 36/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8244 - val_loss: 0.4030 - val_accuracy: 0.7950\n",
            "Epoch 37/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8206 - val_loss: 0.4010 - val_accuracy: 0.8025\n",
            "Epoch 38/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8219 - val_loss: 0.3994 - val_accuracy: 0.8050\n",
            "Epoch 39/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8181 - val_loss: 0.3980 - val_accuracy: 0.8050\n",
            "Epoch 40/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8206 - val_loss: 0.3988 - val_accuracy: 0.8200\n",
            "Epoch 41/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8275 - val_loss: 0.3973 - val_accuracy: 0.8150\n",
            "Epoch 42/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8300 - val_loss: 0.3972 - val_accuracy: 0.8175\n",
            "Epoch 43/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8275 - val_loss: 0.3957 - val_accuracy: 0.8225\n",
            "Epoch 44/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8306 - val_loss: 0.3956 - val_accuracy: 0.8200\n",
            "Epoch 45/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8325 - val_loss: 0.3945 - val_accuracy: 0.8325\n",
            "Epoch 46/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8313 - val_loss: 0.3937 - val_accuracy: 0.8275\n",
            "Epoch 47/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8425 - val_loss: 0.3926 - val_accuracy: 0.8325\n",
            "Epoch 48/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8400 - val_loss: 0.3916 - val_accuracy: 0.8300\n",
            "Epoch 49/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8375 - val_loss: 0.3923 - val_accuracy: 0.8300\n",
            "Epoch 50/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8375 - val_loss: 0.3908 - val_accuracy: 0.8150\n",
            "Epoch 51/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8381 - val_loss: 0.3900 - val_accuracy: 0.8275\n",
            "Epoch 52/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8400 - val_loss: 0.3887 - val_accuracy: 0.8250\n",
            "Epoch 53/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8363 - val_loss: 0.3900 - val_accuracy: 0.8400\n",
            "Epoch 54/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8406 - val_loss: 0.3883 - val_accuracy: 0.8125\n",
            "Epoch 55/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8419 - val_loss: 0.3892 - val_accuracy: 0.8400\n",
            "Epoch 56/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8394 - val_loss: 0.3861 - val_accuracy: 0.8450\n",
            "Epoch 57/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8406 - val_loss: 0.3839 - val_accuracy: 0.8250\n",
            "Epoch 58/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8406 - val_loss: 0.3836 - val_accuracy: 0.8475\n",
            "Epoch 59/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8462 - val_loss: 0.3820 - val_accuracy: 0.8250\n",
            "Epoch 60/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8475 - val_loss: 0.3832 - val_accuracy: 0.8600\n",
            "Epoch 61/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8425 - val_loss: 0.3811 - val_accuracy: 0.8475\n",
            "Epoch 62/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8444 - val_loss: 0.3803 - val_accuracy: 0.8550\n",
            "Epoch 63/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8487 - val_loss: 0.3801 - val_accuracy: 0.8500\n",
            "Epoch 64/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8462 - val_loss: 0.3790 - val_accuracy: 0.8475\n",
            "Epoch 65/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8462 - val_loss: 0.3780 - val_accuracy: 0.8500\n",
            "Epoch 66/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8475 - val_loss: 0.3785 - val_accuracy: 0.8525\n",
            "Epoch 67/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8494 - val_loss: 0.3764 - val_accuracy: 0.8500\n",
            "Epoch 68/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8481 - val_loss: 0.3779 - val_accuracy: 0.8525\n",
            "Epoch 69/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8469 - val_loss: 0.3754 - val_accuracy: 0.8425\n",
            "Epoch 70/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8500 - val_loss: 0.3760 - val_accuracy: 0.8525\n",
            "Epoch 71/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8506 - val_loss: 0.3742 - val_accuracy: 0.8525\n",
            "Epoch 72/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8544 - val_loss: 0.3741 - val_accuracy: 0.8525\n",
            "Epoch 73/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8525 - val_loss: 0.3744 - val_accuracy: 0.8600\n",
            "Epoch 74/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8550 - val_loss: 0.3754 - val_accuracy: 0.8550\n",
            "Epoch 75/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8569 - val_loss: 0.3719 - val_accuracy: 0.8525\n",
            "Epoch 76/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8562 - val_loss: 0.3727 - val_accuracy: 0.8525\n",
            "Epoch 77/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8569 - val_loss: 0.3717 - val_accuracy: 0.8525\n",
            "Epoch 78/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8581 - val_loss: 0.3705 - val_accuracy: 0.8550\n",
            "Epoch 79/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8550 - val_loss: 0.3704 - val_accuracy: 0.8550\n",
            "Epoch 80/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8594 - val_loss: 0.3706 - val_accuracy: 0.8575\n",
            "Epoch 81/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8587 - val_loss: 0.3691 - val_accuracy: 0.8550\n",
            "Epoch 82/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8631 - val_loss: 0.3722 - val_accuracy: 0.8550\n",
            "Epoch 83/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8631 - val_loss: 0.3676 - val_accuracy: 0.8650\n",
            "Epoch 84/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8631 - val_loss: 0.3667 - val_accuracy: 0.8625\n",
            "Epoch 85/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8669 - val_loss: 0.3677 - val_accuracy: 0.8575\n",
            "Epoch 86/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8669 - val_loss: 0.3653 - val_accuracy: 0.8550\n",
            "Epoch 87/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8656 - val_loss: 0.3657 - val_accuracy: 0.8675\n",
            "Epoch 88/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8656 - val_loss: 0.3651 - val_accuracy: 0.8675\n",
            "Epoch 89/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8675 - val_loss: 0.3662 - val_accuracy: 0.8625\n",
            "Epoch 90/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8694 - val_loss: 0.3641 - val_accuracy: 0.8625\n",
            "Epoch 91/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8681 - val_loss: 0.3646 - val_accuracy: 0.8575\n",
            "Epoch 92/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8731 - val_loss: 0.3620 - val_accuracy: 0.8625\n",
            "Epoch 93/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8750 - val_loss: 0.3608 - val_accuracy: 0.8600\n",
            "Epoch 94/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8719 - val_loss: 0.3598 - val_accuracy: 0.8600\n",
            "Epoch 95/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8744 - val_loss: 0.3598 - val_accuracy: 0.8550\n",
            "Epoch 96/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8737 - val_loss: 0.3580 - val_accuracy: 0.8600\n",
            "Epoch 97/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8737 - val_loss: 0.3564 - val_accuracy: 0.8575\n",
            "Epoch 98/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.8756 - val_loss: 0.3578 - val_accuracy: 0.8600\n",
            "Epoch 99/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.8731 - val_loss: 0.3576 - val_accuracy: 0.8600\n",
            "Epoch 100/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8763 - val_loss: 0.3552 - val_accuracy: 0.8575\n",
            "Epoch 101/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8781 - val_loss: 0.3556 - val_accuracy: 0.8550\n",
            "Epoch 102/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8788 - val_loss: 0.3522 - val_accuracy: 0.8650\n",
            "Epoch 103/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8800 - val_loss: 0.3533 - val_accuracy: 0.8575\n",
            "Epoch 104/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8800 - val_loss: 0.3532 - val_accuracy: 0.8650\n",
            "Epoch 105/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8831 - val_loss: 0.3554 - val_accuracy: 0.8550\n",
            "Epoch 106/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8763 - val_loss: 0.3514 - val_accuracy: 0.8650\n",
            "Epoch 107/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8838 - val_loss: 0.3531 - val_accuracy: 0.8575\n",
            "Epoch 108/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.8875 - val_loss: 0.3520 - val_accuracy: 0.8550\n",
            "Epoch 109/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8844 - val_loss: 0.3514 - val_accuracy: 0.8600\n",
            "Epoch 110/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.8838 - val_loss: 0.3517 - val_accuracy: 0.8675\n",
            "Epoch 111/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8869 - val_loss: 0.3517 - val_accuracy: 0.8600\n",
            "Epoch 112/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8838 - val_loss: 0.3539 - val_accuracy: 0.8600\n",
            "Epoch 113/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8863 - val_loss: 0.3530 - val_accuracy: 0.8600\n",
            "Epoch 114/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.8888 - val_loss: 0.3490 - val_accuracy: 0.8550\n",
            "Epoch 115/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.8863 - val_loss: 0.3488 - val_accuracy: 0.8600\n",
            "Epoch 116/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8888 - val_loss: 0.3498 - val_accuracy: 0.8550\n",
            "Epoch 117/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8850 - val_loss: 0.3483 - val_accuracy: 0.8550\n",
            "Epoch 118/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8875 - val_loss: 0.3492 - val_accuracy: 0.8550\n",
            "Epoch 119/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.8850 - val_loss: 0.3491 - val_accuracy: 0.8500\n",
            "Epoch 120/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8888 - val_loss: 0.3528 - val_accuracy: 0.8550\n",
            "Epoch 121/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8881 - val_loss: 0.3497 - val_accuracy: 0.8550\n",
            "Epoch 122/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.8900 - val_loss: 0.3469 - val_accuracy: 0.8575\n",
            "Epoch 123/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.8925 - val_loss: 0.3492 - val_accuracy: 0.8550\n",
            "Epoch 124/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8881 - val_loss: 0.3471 - val_accuracy: 0.8500\n",
            "Epoch 125/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8950 - val_loss: 0.3486 - val_accuracy: 0.8550\n",
            "Epoch 126/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.8875 - val_loss: 0.3469 - val_accuracy: 0.8525\n",
            "Epoch 127/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8919 - val_loss: 0.3472 - val_accuracy: 0.8550\n",
            "Epoch 128/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8950 - val_loss: 0.3466 - val_accuracy: 0.8525\n",
            "Epoch 129/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8900 - val_loss: 0.3474 - val_accuracy: 0.8600\n",
            "Epoch 130/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8931 - val_loss: 0.3466 - val_accuracy: 0.8550\n",
            "Epoch 131/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8906 - val_loss: 0.3467 - val_accuracy: 0.8575\n",
            "Epoch 132/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.8938 - val_loss: 0.3470 - val_accuracy: 0.8575\n",
            "Epoch 133/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8969 - val_loss: 0.3479 - val_accuracy: 0.8600\n",
            "Epoch 134/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8938 - val_loss: 0.3467 - val_accuracy: 0.8575\n",
            "Epoch 135/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8938 - val_loss: 0.3463 - val_accuracy: 0.8550\n",
            "Epoch 136/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.8963 - val_loss: 0.3470 - val_accuracy: 0.8600\n",
            "Epoch 137/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8938 - val_loss: 0.3461 - val_accuracy: 0.8600\n",
            "Epoch 138/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.8906 - val_loss: 0.3462 - val_accuracy: 0.8575\n",
            "Epoch 139/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.8975 - val_loss: 0.3477 - val_accuracy: 0.8550\n",
            "Epoch 140/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.8900 - val_loss: 0.3432 - val_accuracy: 0.8550\n",
            "Epoch 141/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8963 - val_loss: 0.3451 - val_accuracy: 0.8575\n",
            "Epoch 142/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.8963 - val_loss: 0.3465 - val_accuracy: 0.8575\n",
            "Epoch 143/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.8913 - val_loss: 0.3466 - val_accuracy: 0.8600\n",
            "Epoch 144/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.8950 - val_loss: 0.3428 - val_accuracy: 0.8475\n",
            "Epoch 145/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.8938 - val_loss: 0.3463 - val_accuracy: 0.8600\n",
            "Epoch 146/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.8944 - val_loss: 0.3450 - val_accuracy: 0.8525\n",
            "Epoch 147/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.8963 - val_loss: 0.3439 - val_accuracy: 0.8600\n",
            "Epoch 148/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.8938 - val_loss: 0.3448 - val_accuracy: 0.8500\n",
            "Epoch 149/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.8956 - val_loss: 0.3448 - val_accuracy: 0.8600\n",
            "Epoch 150/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.8963 - val_loss: 0.3424 - val_accuracy: 0.8525\n",
            "Epoch 151/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.8981 - val_loss: 0.3434 - val_accuracy: 0.8500\n",
            "Epoch 152/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.8956 - val_loss: 0.3427 - val_accuracy: 0.8550\n",
            "Epoch 153/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.8994 - val_loss: 0.3435 - val_accuracy: 0.8550\n",
            "Epoch 154/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.8956 - val_loss: 0.3431 - val_accuracy: 0.8575\n",
            "Epoch 155/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.8969 - val_loss: 0.3465 - val_accuracy: 0.8550\n",
            "Epoch 156/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8956 - val_loss: 0.3414 - val_accuracy: 0.8625\n",
            "Epoch 157/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8969 - val_loss: 0.3407 - val_accuracy: 0.8550\n",
            "Epoch 158/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.8956 - val_loss: 0.3427 - val_accuracy: 0.8550\n",
            "Epoch 159/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.9000 - val_loss: 0.3400 - val_accuracy: 0.8600\n",
            "Epoch 160/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8975 - val_loss: 0.3398 - val_accuracy: 0.8550\n",
            "Epoch 161/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8988 - val_loss: 0.3407 - val_accuracy: 0.8550\n",
            "Epoch 162/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.9019 - val_loss: 0.3404 - val_accuracy: 0.8550\n",
            "Epoch 163/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9019 - val_loss: 0.3396 - val_accuracy: 0.8600\n",
            "Epoch 164/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9025 - val_loss: 0.3386 - val_accuracy: 0.8500\n",
            "Epoch 165/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.8969 - val_loss: 0.3374 - val_accuracy: 0.8650\n",
            "Epoch 166/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.9013 - val_loss: 0.3404 - val_accuracy: 0.8675\n",
            "Epoch 167/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8956 - val_loss: 0.3380 - val_accuracy: 0.8550\n",
            "Epoch 168/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9031 - val_loss: 0.3383 - val_accuracy: 0.8650\n",
            "Epoch 169/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9031 - val_loss: 0.3374 - val_accuracy: 0.8700\n",
            "Epoch 170/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9025 - val_loss: 0.3397 - val_accuracy: 0.8575\n",
            "Epoch 171/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9038 - val_loss: 0.3352 - val_accuracy: 0.8650\n",
            "Epoch 172/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2410 - accuracy: 0.8994 - val_loss: 0.3345 - val_accuracy: 0.8650\n",
            "Epoch 173/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.8994 - val_loss: 0.3346 - val_accuracy: 0.8650\n",
            "Epoch 174/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9031 - val_loss: 0.3351 - val_accuracy: 0.8650\n",
            "Epoch 175/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9044 - val_loss: 0.3338 - val_accuracy: 0.8650\n",
            "Epoch 176/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2364 - accuracy: 0.9062 - val_loss: 0.3363 - val_accuracy: 0.8600\n",
            "Epoch 177/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.9019 - val_loss: 0.3326 - val_accuracy: 0.8650\n",
            "Epoch 178/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9069 - val_loss: 0.3329 - val_accuracy: 0.8700\n",
            "Epoch 179/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9050 - val_loss: 0.3311 - val_accuracy: 0.8650\n",
            "Epoch 180/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9031 - val_loss: 0.3317 - val_accuracy: 0.8650\n",
            "Epoch 181/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9050 - val_loss: 0.3317 - val_accuracy: 0.8650\n",
            "Epoch 182/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.9050 - val_loss: 0.3321 - val_accuracy: 0.8650\n",
            "Epoch 183/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9075 - val_loss: 0.3311 - val_accuracy: 0.8650\n",
            "Epoch 184/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9075 - val_loss: 0.3326 - val_accuracy: 0.8625\n",
            "Epoch 185/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9050 - val_loss: 0.3298 - val_accuracy: 0.8650\n",
            "Epoch 186/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9062 - val_loss: 0.3285 - val_accuracy: 0.8650\n",
            "Epoch 187/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9050 - val_loss: 0.3300 - val_accuracy: 0.8600\n",
            "Epoch 188/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9094 - val_loss: 0.3285 - val_accuracy: 0.8650\n",
            "Epoch 189/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9069 - val_loss: 0.3319 - val_accuracy: 0.8675\n",
            "Epoch 190/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9075 - val_loss: 0.3313 - val_accuracy: 0.8650\n",
            "Epoch 191/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9106 - val_loss: 0.3295 - val_accuracy: 0.8600\n",
            "Epoch 192/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9094 - val_loss: 0.3292 - val_accuracy: 0.8650\n",
            "Epoch 193/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9100 - val_loss: 0.3315 - val_accuracy: 0.8650\n",
            "Epoch 194/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9100 - val_loss: 0.3291 - val_accuracy: 0.8625\n",
            "Epoch 195/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9075 - val_loss: 0.3273 - val_accuracy: 0.8650\n",
            "Epoch 196/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9131 - val_loss: 0.3295 - val_accuracy: 0.8550\n",
            "Epoch 197/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9075 - val_loss: 0.3311 - val_accuracy: 0.8700\n",
            "Epoch 198/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9100 - val_loss: 0.3279 - val_accuracy: 0.8700\n",
            "Epoch 199/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9156 - val_loss: 0.3279 - val_accuracy: 0.8575\n",
            "Epoch 200/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9150 - val_loss: 0.3292 - val_accuracy: 0.8650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ab9b29a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3182793a-c9d1-49a8-e289-a4178d14fbf5"
      },
      "source": [
        "prediction = round(predict_diabetes(1, 120, 90, 27, 149, 33.4, 0.393, 42))\n",
        "if prediction:\n",
        "  print('Sorry! You have diabetes.')\n",
        "else:\n",
        "  print(\"Voila! You don't have diabetes.\")"
      ],
      "id": "8ab9b29a",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sorry! You have diabetes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a3c7471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114efc0e-de17-40d5-d7f7-64c942ea186f"
      },
      "source": [
        "model_h = get_model_heart()"
      ],
      "id": "2a3c7471",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train size: (242, 13), x_test size: (61, 13)\n",
            "y_train size: (242,), y_test size: (61,)\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 21ms/step - loss: 0.7871 - accuracy: 0.4587 - val_loss: 0.8094 - val_accuracy: 0.4426\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7485 - accuracy: 0.4587 - val_loss: 0.7730 - val_accuracy: 0.4426\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7150 - accuracy: 0.4587 - val_loss: 0.7470 - val_accuracy: 0.4262\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.4587 - val_loss: 0.7252 - val_accuracy: 0.4426\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6714 - accuracy: 0.4711 - val_loss: 0.7068 - val_accuracy: 0.4426\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6534 - accuracy: 0.4959 - val_loss: 0.6909 - val_accuracy: 0.4262\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.5496 - val_loss: 0.6768 - val_accuracy: 0.4590\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6240 - accuracy: 0.6116 - val_loss: 0.6636 - val_accuracy: 0.5082\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.6570 - val_loss: 0.6504 - val_accuracy: 0.5410\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.6901 - val_loss: 0.6381 - val_accuracy: 0.5902\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.7190 - val_loss: 0.6263 - val_accuracy: 0.6393\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.7314 - val_loss: 0.6149 - val_accuracy: 0.6393\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5597 - accuracy: 0.7438 - val_loss: 0.6044 - val_accuracy: 0.6393\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.7603 - val_loss: 0.5929 - val_accuracy: 0.6885\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.7851 - val_loss: 0.5808 - val_accuracy: 0.7049\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5188 - accuracy: 0.7893 - val_loss: 0.5685 - val_accuracy: 0.7049\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7934 - val_loss: 0.5569 - val_accuracy: 0.7049\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7975 - val_loss: 0.5454 - val_accuracy: 0.7541\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.8017 - val_loss: 0.5343 - val_accuracy: 0.7541\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.8099 - val_loss: 0.5241 - val_accuracy: 0.7705\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.8140 - val_loss: 0.5143 - val_accuracy: 0.7705\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.8182 - val_loss: 0.5042 - val_accuracy: 0.7705\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.8264 - val_loss: 0.4955 - val_accuracy: 0.7705\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8264 - val_loss: 0.4875 - val_accuracy: 0.7705\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8223 - val_loss: 0.4805 - val_accuracy: 0.7705\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8264 - val_loss: 0.4747 - val_accuracy: 0.7705\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8306 - val_loss: 0.4684 - val_accuracy: 0.7705\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8347 - val_loss: 0.4633 - val_accuracy: 0.7705\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8347 - val_loss: 0.4578 - val_accuracy: 0.7705\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3667 - accuracy: 0.8430 - val_loss: 0.4532 - val_accuracy: 0.7705\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8430 - val_loss: 0.4501 - val_accuracy: 0.7541\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8430 - val_loss: 0.4477 - val_accuracy: 0.7541\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8512 - val_loss: 0.4458 - val_accuracy: 0.7541\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8512 - val_loss: 0.4429 - val_accuracy: 0.7541\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8512 - val_loss: 0.4425 - val_accuracy: 0.7705\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8512 - val_loss: 0.4413 - val_accuracy: 0.7705\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8512 - val_loss: 0.4400 - val_accuracy: 0.7705\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8512 - val_loss: 0.4381 - val_accuracy: 0.7705\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8512 - val_loss: 0.4366 - val_accuracy: 0.7705\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3250 - accuracy: 0.8554 - val_loss: 0.4347 - val_accuracy: 0.7869\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3213 - accuracy: 0.8554 - val_loss: 0.4340 - val_accuracy: 0.7869\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3191 - accuracy: 0.8554 - val_loss: 0.4324 - val_accuracy: 0.7869\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3157 - accuracy: 0.8636 - val_loss: 0.4311 - val_accuracy: 0.7869\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3134 - accuracy: 0.8595 - val_loss: 0.4315 - val_accuracy: 0.7869\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8636 - val_loss: 0.4305 - val_accuracy: 0.7869\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3079 - accuracy: 0.8678 - val_loss: 0.4298 - val_accuracy: 0.7869\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3051 - accuracy: 0.8719 - val_loss: 0.4282 - val_accuracy: 0.7705\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3026 - accuracy: 0.8760 - val_loss: 0.4278 - val_accuracy: 0.7705\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3000 - accuracy: 0.8760 - val_loss: 0.4268 - val_accuracy: 0.7705\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.8802 - val_loss: 0.4267 - val_accuracy: 0.7705\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2953 - accuracy: 0.8802 - val_loss: 0.4276 - val_accuracy: 0.7705\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.8843 - val_loss: 0.4277 - val_accuracy: 0.7705\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8843 - val_loss: 0.4276 - val_accuracy: 0.7705\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2882 - accuracy: 0.8843 - val_loss: 0.4264 - val_accuracy: 0.7705\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2861 - accuracy: 0.8843 - val_loss: 0.4279 - val_accuracy: 0.7705\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2836 - accuracy: 0.8843 - val_loss: 0.4267 - val_accuracy: 0.7705\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2813 - accuracy: 0.8884 - val_loss: 0.4260 - val_accuracy: 0.7705\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2791 - accuracy: 0.8843 - val_loss: 0.4250 - val_accuracy: 0.7705\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2765 - accuracy: 0.8884 - val_loss: 0.4252 - val_accuracy: 0.7705\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2742 - accuracy: 0.8884 - val_loss: 0.4257 - val_accuracy: 0.7705\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2717 - accuracy: 0.8884 - val_loss: 0.4252 - val_accuracy: 0.7705\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2692 - accuracy: 0.8884 - val_loss: 0.4248 - val_accuracy: 0.7705\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2671 - accuracy: 0.8884 - val_loss: 0.4250 - val_accuracy: 0.7705\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2644 - accuracy: 0.8926 - val_loss: 0.4244 - val_accuracy: 0.7705\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2621 - accuracy: 0.8926 - val_loss: 0.4251 - val_accuracy: 0.7705\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2599 - accuracy: 0.8926 - val_loss: 0.4254 - val_accuracy: 0.7705\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2582 - accuracy: 0.8926 - val_loss: 0.4247 - val_accuracy: 0.7705\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2561 - accuracy: 0.8926 - val_loss: 0.4239 - val_accuracy: 0.7705\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2541 - accuracy: 0.8926 - val_loss: 0.4235 - val_accuracy: 0.7705\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2517 - accuracy: 0.8926 - val_loss: 0.4242 - val_accuracy: 0.7705\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2496 - accuracy: 0.8926 - val_loss: 0.4258 - val_accuracy: 0.7705\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2480 - accuracy: 0.8926 - val_loss: 0.4246 - val_accuracy: 0.7869\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2459 - accuracy: 0.8967 - val_loss: 0.4244 - val_accuracy: 0.8033\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2434 - accuracy: 0.8926 - val_loss: 0.4233 - val_accuracy: 0.8033\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2414 - accuracy: 0.8926 - val_loss: 0.4216 - val_accuracy: 0.8033\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2393 - accuracy: 0.8926 - val_loss: 0.4216 - val_accuracy: 0.8033\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2373 - accuracy: 0.8926 - val_loss: 0.4218 - val_accuracy: 0.8033\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2353 - accuracy: 0.8967 - val_loss: 0.4202 - val_accuracy: 0.8033\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2330 - accuracy: 0.8967 - val_loss: 0.4185 - val_accuracy: 0.8033\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2310 - accuracy: 0.9008 - val_loss: 0.4196 - val_accuracy: 0.8033\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2286 - accuracy: 0.9050 - val_loss: 0.4190 - val_accuracy: 0.8033\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2266 - accuracy: 0.9050 - val_loss: 0.4191 - val_accuracy: 0.8033\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2244 - accuracy: 0.9050 - val_loss: 0.4179 - val_accuracy: 0.8033\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2224 - accuracy: 0.9091 - val_loss: 0.4160 - val_accuracy: 0.8033\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9050 - val_loss: 0.4158 - val_accuracy: 0.8033\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2183 - accuracy: 0.9091 - val_loss: 0.4143 - val_accuracy: 0.8033\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9091 - val_loss: 0.4138 - val_accuracy: 0.8033\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2143 - accuracy: 0.9091 - val_loss: 0.4143 - val_accuracy: 0.8033\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2120 - accuracy: 0.9091 - val_loss: 0.4175 - val_accuracy: 0.8033\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2107 - accuracy: 0.9132 - val_loss: 0.4181 - val_accuracy: 0.7705\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2080 - accuracy: 0.9132 - val_loss: 0.4189 - val_accuracy: 0.7705\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2058 - accuracy: 0.9215 - val_loss: 0.4197 - val_accuracy: 0.7705\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2039 - accuracy: 0.9256 - val_loss: 0.4193 - val_accuracy: 0.7705\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2023 - accuracy: 0.9256 - val_loss: 0.4201 - val_accuracy: 0.7705\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2004 - accuracy: 0.9256 - val_loss: 0.4204 - val_accuracy: 0.7705\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1983 - accuracy: 0.9256 - val_loss: 0.4214 - val_accuracy: 0.7705\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1964 - accuracy: 0.9256 - val_loss: 0.4225 - val_accuracy: 0.7705\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1944 - accuracy: 0.9256 - val_loss: 0.4219 - val_accuracy: 0.7705\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1927 - accuracy: 0.9256 - val_loss: 0.4224 - val_accuracy: 0.7705\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1908 - accuracy: 0.9256 - val_loss: 0.4220 - val_accuracy: 0.7705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85a8eeba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df08534e-5a8a-4235-e052-18e3e69d0343"
      },
      "source": [
        "prediction = round(predict_heart(54,1,0,140,239,0,1,160,0,1.2,2,0,2))\n",
        "if prediction:\n",
        "  print('Sorry! You have heart disease.')\n",
        "else:\n",
        "  print(\"Voila! You don't have heart disease.\")"
      ],
      "id": "85a8eeba",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sorry! You have heart disease.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f2d4e80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abeda70-24aa-4de2-d90c-26e62dfc6208"
      },
      "source": [
        "model_s = get_model_stroke()"
      ],
      "id": "4f2d4e80",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train size: (800, 10), x_test size: (201, 10)\n",
            "y_train size: (800,), y_test size: (201,)\n",
            "Epoch 1/25\n",
            "25/25 [==============================] - 1s 8ms/step - loss: 0.7493 - accuracy: 0.4450 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
            "Epoch 2/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.6975 - val_loss: 0.5200 - val_accuracy: 0.8159\n",
            "Epoch 3/25\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7250 - val_loss: 0.4577 - val_accuracy: 0.8209\n",
            "Epoch 4/25\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7325 - val_loss: 0.4255 - val_accuracy: 0.8209\n",
            "Epoch 5/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7337 - val_loss: 0.4069 - val_accuracy: 0.8209\n",
            "Epoch 6/25\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7337 - val_loss: 0.3935 - val_accuracy: 0.8209\n",
            "Epoch 7/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7337 - val_loss: 0.3837 - val_accuracy: 0.8209\n",
            "Epoch 8/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7325 - val_loss: 0.3769 - val_accuracy: 0.8259\n",
            "Epoch 9/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7337 - val_loss: 0.3703 - val_accuracy: 0.8259\n",
            "Epoch 10/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7387 - val_loss: 0.3657 - val_accuracy: 0.8308\n",
            "Epoch 11/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7462 - val_loss: 0.3599 - val_accuracy: 0.8358\n",
            "Epoch 12/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7500 - val_loss: 0.3533 - val_accuracy: 0.8358\n",
            "Epoch 13/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7538 - val_loss: 0.3513 - val_accuracy: 0.8308\n",
            "Epoch 14/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7738 - val_loss: 0.3467 - val_accuracy: 0.8408\n",
            "Epoch 15/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7800 - val_loss: 0.3448 - val_accuracy: 0.8507\n",
            "Epoch 16/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7850 - val_loss: 0.3399 - val_accuracy: 0.8557\n",
            "Epoch 17/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7900 - val_loss: 0.3392 - val_accuracy: 0.8607\n",
            "Epoch 18/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7987 - val_loss: 0.3355 - val_accuracy: 0.8607\n",
            "Epoch 19/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.7975 - val_loss: 0.3365 - val_accuracy: 0.8607\n",
            "Epoch 20/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8050 - val_loss: 0.3332 - val_accuracy: 0.8607\n",
            "Epoch 21/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8075 - val_loss: 0.3325 - val_accuracy: 0.8557\n",
            "Epoch 22/25\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8075 - val_loss: 0.3328 - val_accuracy: 0.8657\n",
            "Epoch 23/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8100 - val_loss: 0.3320 - val_accuracy: 0.8657\n",
            "Epoch 24/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8087 - val_loss: 0.3297 - val_accuracy: 0.8607\n",
            "Epoch 25/25\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8075 - val_loss: 0.3326 - val_accuracy: 0.8607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ebb38b0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e9b9ed-f0b2-45cd-e959-ad7831d8b36f"
      },
      "source": [
        "prediction = round(predict_stroke(0,68,0,1,1,1,0,200.69,36.6,0))\n",
        "if prediction:\n",
        "  print('Sorry! You have Stroke.')\n",
        "else:\n",
        "  print(\"Voila! You don't have Stroke.\")"
      ],
      "id": "ebb38b0e",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sorry! You have Stroke.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "417e3d93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af99e0a4-f150-4221-89f8-fadfbc643552"
      },
      "source": [
        "saved_model_path = \"./my_model.h5\"\n",
        "\n",
        "model_d.save(\"./diabetes/model_diabetes.h5\")\n",
        "model_h.save(\"./heart/model_heart.h5\")\n",
        "model_s.save(\"./stroke/model_stroke.h5\")\n",
        "\n",
        "!tensorflowjs_converter --input_format=keras {\"./diabetes/model_diabetes.h5\"} ./diabetes/\n",
        "!tensorflowjs_converter --input_format=keras {\"./heart/model_heart.h5\"} ./heart/\n",
        "!tensorflowjs_converter --input_format=keras {\"./stroke/model_stroke.h5\"} ./stroke/"
      ],
      "id": "417e3d93",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-01 14:32:47.900582: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-01 14:32:50.837103: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-01 14:32:53.566221: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv8zKNQO9WuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a69167b-7f70-405a-9ad7-740faafd44ec"
      },
      "source": [
        "tf.saved_model.save(model_s, \"./heart/1\")\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"./heart/1\")\n",
        "tflite_model = converter.convert()\n",
        "tflite_model_file = pathlib.Path('./heart/model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "id": "Tv8zKNQO9WuY",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: ./heart/1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3712"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRsHoagg9WjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10059b97-63ef-44d6-cc5b-689b35e3bda8"
      },
      "source": [
        "tf.saved_model.save(model_s, \"./diabetes/1\")\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"./diabetes/1\")\n",
        "tflite_model = converter.convert()\n",
        "tflite_model_file = pathlib.Path('./diabetes/model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "id": "zRsHoagg9WjV",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: ./diabetes/1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3712"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0381e083",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131809a1-d4b1-46d7-f879-335e602e35e9"
      },
      "source": [
        "tf.saved_model.save(model_s, \"./stroke/1\")\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"./stroke/1\")\n",
        "tflite_model = converter.convert()\n",
        "tflite_model_file = pathlib.Path('./stroke/model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "id": "0381e083",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: ./stroke/1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3712"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WJrN2jM-Vxi",
        "outputId": "518f84a4-68b7-445f-a6e9-228c0b4bb9bb"
      },
      "source": [
        "!zip -r ./diabetes.zip ./diabetes/\n",
        "!zip -r ./heart.zip ./heart/\n",
        "!zip -r ./stroke.zip ./stroke/"
      ],
      "id": "_WJrN2jM-Vxi",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: diabetes/ (stored 0%)\n",
            "  adding: diabetes/model.tflite (deflated 29%)\n",
            "  adding: diabetes/1/ (stored 0%)\n",
            "  adding: diabetes/1/saved_model.pb (deflated 87%)\n",
            "  adding: diabetes/1/variables/ (stored 0%)\n",
            "  adding: diabetes/1/variables/variables.data-00000-of-00001 (deflated 36%)\n",
            "  adding: diabetes/1/variables/variables.index (deflated 63%)\n",
            "  adding: diabetes/1/assets/ (stored 0%)\n",
            "  adding: diabetes/model_diabetes.h5 (deflated 79%)\n",
            "  adding: diabetes/group1-shard1of1.bin (deflated 4%)\n",
            "  adding: diabetes/model.json (deflated 74%)\n",
            "  adding: heart/ (stored 0%)\n",
            "  adding: heart/model.tflite (deflated 29%)\n",
            "  adding: heart/1/ (stored 0%)\n",
            "  adding: heart/1/saved_model.pb (deflated 88%)\n",
            "  adding: heart/1/variables/ (stored 0%)\n",
            "  adding: heart/1/variables/variables.data-00000-of-00001 (deflated 36%)\n",
            "  adding: heart/1/variables/variables.index (deflated 63%)\n",
            "  adding: heart/1/assets/ (stored 0%)\n",
            "  adding: heart/model_heart.h5 (deflated 78%)\n",
            "  adding: heart/group1-shard1of1.bin (deflated 5%)\n",
            "  adding: heart/model.json (deflated 74%)\n",
            "  adding: stroke/ (stored 0%)\n",
            "  adding: stroke/model.tflite (deflated 29%)\n",
            "  adding: stroke/1/ (stored 0%)\n",
            "  adding: stroke/1/saved_model.pb (deflated 88%)\n",
            "  adding: stroke/1/variables/ (stored 0%)\n",
            "  adding: stroke/1/variables/variables.data-00000-of-00001 (deflated 36%)\n",
            "  adding: stroke/1/variables/variables.index (deflated 63%)\n",
            "  adding: stroke/1/assets/ (stored 0%)\n",
            "  adding: stroke/group1-shard1of1.bin (deflated 5%)\n",
            "  adding: stroke/model_stroke.h5 (deflated 78%)\n",
            "  adding: stroke/model.json (deflated 74%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biO6pYTC-k3z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5349d682-0fd5-4e95-b40f-9f3342236a2a"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"./diabetes.zip\")\n",
        "files.download(\"./heart.zip\")\n",
        "files.download(\"./stroke.zip\")"
      ],
      "id": "biO6pYTC-k3z",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1cd6c48a-123d-49fb-8c91-0ee4f3439032\", \"diabetes.zip\", 33752)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8e6e83c1-22be-4569-a2de-70e261e57eab\", \"heart.zip\", 34290)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2ee3847a-0c3e-40c1-88ad-c9d002db1a6d\", \"stroke.zip\", 33621)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppHSsNfY_OTC"
      },
      "source": [
        ""
      ],
      "id": "ppHSsNfY_OTC",
      "execution_count": 19,
      "outputs": []
    }
  ]
}